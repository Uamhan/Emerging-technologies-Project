{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Dataset\n",
    "\n",
    "The MNIST (modified national institute of standards and technology) Dataset  is a a computer vision dataset. it consists of 60,000 training datapoints and 10,000 testing datapoints. Each datapoint consists of a 28x28 pixel image. This image represents a handwriten digit. The MNIST dataset is a sub set of the much larger NIST dataset where by the digits have been size normalised to the 28x28 pixel size and they have been centrered. This formating and pre processing allows for a normailsed dataset so that we can get as acurate as possible results from our machine learning algorythms.\n",
    "\n",
    "For machine learning classification we need fetures and labels for the data. Features being the peices of information or varibles for each datapoint and the label being the classification assigned to that datapoint. We previously discused the IRIS dataset in another notebook in this repository whereby there was 4 features and a label for each datapoint. The MNIST data set is a little more complex. For each datapoint we have a 28x28 pixel image and a label stateing what number that image is ment to represent. \n",
    "\n",
    "This 28x28 pixel image is represented by a numpy array with the shape (28,28) with each digit in the array represent a pixel. Each value iin this array ranges between 0 and 1. 0 being white 1 being black and the numbers between being varrying degrees of gray. as shown by the image below from Christopher Olahs blog on The MNIST Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/MNIST_Array.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To suit our purposes of machinelearning we need to reformat this data so that we can split it into individual features as discused earlyer. To do this we simmply flatten the 28x28 array into 784 dimensional vector. now we have 784 individual varibles or features describing the intensity of a pixel at a given point in the image. we can now have a datapoint we can use. \n",
    "\n",
    "with the IRIS dataset we had datapoints that had 4 features and 1 label now after flattening the arrays representing the images we have a dataset that's datapoints have 784 features and 1 label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy for use of efficent arrays.\n",
    "import numpy as np\n",
    "#import pandas for reading iin the csv file.\n",
    "import pandas as pd\n",
    "#import matplotlib to plot graphs.\n",
    "import matplotlib.pyplot as plt\n",
    "#import the train.csv file which contains data into a varible called data.\n",
    "data = pd.read_csv('./resources/train.csv')\n",
    "\n",
    "#shows that we have 785 columns per row and 42,000 rows. \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a simple representation of this data we will plot the information in a given row as a 28x28 pixel grid and print the label beneth to show that the training file we imported acctualy dose represent the hand written digits of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#creates array of labels called l\n",
    "l = data['label']\n",
    "#creates array with all but the labels called d\n",
    "d = data.drop(\"label\",axis=1) \n",
    "#sets the image size for the plot\n",
    "plt.figure(figsize=(7,7))\n",
    "#changeable index value which selects with datapoint to display bellow\n",
    "#you can change this value as you please to see other values from the data set.\n",
    "index = 90\n",
    "#shapes the dataframe at the given index back to a 28x28 array\n",
    "shapedData = d.iloc[index].values.reshape(28,28)\n",
    "#plots the reshaped datapoint as an image useing the grayscale cmap with no interpolation\n",
    "plt.imshow(shapedData,interpolation=\"none\",cmap=\"gray\")\n",
    "#shows plot\n",
    "plt.show()\n",
    "#prints the label of the same ploted image.\n",
    "print(l[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
