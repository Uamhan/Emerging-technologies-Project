{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Dataset\n",
    "\n",
    "The MNIST (modified national institute of standards and technology) Dataset  is a a computer vision dataset. it consists of 60,000 training datapoints and 10,000 testing datapoints. Each datapoint consists of a 28x28 pixel image. This image represents a handwriten digit. The MNIST dataset is a sub set of the much larger NIST dataset where by the digits have been size normalised to the 28x28 pixel size and they have been centrered. This formating and pre processing allows for a normailsed dataset so that we can get as acurate as possible results from our machine learning algorythms.\n",
    "\n",
    "For machine learning classification we need fetures and labels for the data. Features being the peices of information or varibles for each datapoint and the label being the classification assigned to that datapoint. We previously discused the IRIS dataset in another notebook in this repository whereby there was 4 features and a label for each datapoint. The MNIST data set is a little more complex. For each datapoint we have a 28x28 pixel image and a label stateing what number that image is ment to represent. \n",
    "\n",
    "This 28x28 pixel image is represented by a numpy array with the shape (28,28) with each digit in the array represent a pixel. Each value in this array ranges between 0 and 1. 0 being white 1 being black and the numbers between being varrying degrees of gray. as shown by the image below from Christopher Olahs blog on The MNIST Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/MNIST_Array.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To suit our purposes of machinelearning we need to reformat this data so that we can split it into individual features as discused earlyer. To do this we simmply flatten the 28x28 array into 784 dimensional vector. now we have 784 individual varibles or features describing the intensity of a pixel at a given point in the image. we now have a datapoint we can use. \n",
    "\n",
    "with the IRIS dataset we had datapoints that had 4 features and 1 label now after flattening the arrays representing the images we have a dataset that's datapoints have 784 features and 1 label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy for use of efficent arrays.\n",
    "import numpy as np\n",
    "#import pandas for reading iin the csv file.\n",
    "import pandas as pd\n",
    "#import matplotlib to plot graphs.\n",
    "import matplotlib.pyplot as plt\n",
    "#import the train.csv file which contains data into a varible called data.\n",
    "data = pd.read_csv('./resources/train.csv')\n",
    "\n",
    "#shows that we have 785 columns per row and 42,000 rows. \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a simple representation of this data we will plot the information in a given row as a 28x28 pixel grid and print the label beneth to show that the training file we imported acctualy dose represent the hand written digits of the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#creates array of labels called l\n",
    "l = data['label']\n",
    "#creates array with all but the labels called d\n",
    "d = data.drop(\"label\",axis=1) \n",
    "#sets the image size for the plot\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "\n",
    "#changeable index value which selects with datapoint to display bellow\n",
    "#you can change this value as you please to see other values from the data set.\n",
    "index = 41999\n",
    "\n",
    "\n",
    "#shapes the dataframe at the given index back to a 28x28 array\n",
    "shapedData = d.iloc[index].values.reshape(28,28)\n",
    "#plots the reshaped datapoint as an image useing the grayscale cmap with no interpolation\n",
    "plt.imshow(shapedData,interpolation=\"none\",cmap=\"gray\")\n",
    "#shows plot\n",
    "plt.show()\n",
    "#prints the label of the same ploted image.\n",
    "print(l[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try changeing the index in the code above and ass you can see a difrent image will be drawn and its label will be printed bellow it. as long as the index is under 42000 as that is the number of enterys in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficiency.\n",
    "\n",
    "As seen above we have a simple implementation of the MNIST dataset we simply loaded the csv file into memory using pandas read_csv functionality and while this may be sufficent for browseing the data and displaying individual datapoints from the dataset as seen above. This would prove very ineffeciant to use for machine learning. As we saw with the Iris dataset we had 150 data points each with 4 features and 1 label. To simplify we had 750 peices of information(150x5). This is a very small set of data and as such did not require much change to get quick results. Now take the MNIST data set we have 784 features and 1 label per data point and in this example 42,000 datapoints or again to simplify 32,970,000(785x42000) peices of information. This institutes a need for us to more efficently load this data into memory so training our suprovised machine learning algorythms do not take excesive amounts of time.\n",
    "\n",
    "Most common machine learning packages such as tensorflow contain predefind methods that will load the MNIST dataset into memory incredibly efficently as it is such a widely used dataset for study and education.\n",
    "\n",
    "We can modify the data most commonly with a python package known as theano which is used to optomise manipulate and evaluate mathematical expresions. this allows us to omptimse the data for GPU(Graphics Processing Unit) processing. \n",
    "\n",
    "We load our data into whats know as a shared varible. Shared Variables are a feature of the programming language which allows programs running on one processor to share information with another processor or in this case the GPU. \n",
    "\n",
    "To process on a GPU we want the values to be floats as GPU's accel at floating point calculations. This speed is why we wish to optimise for the the gpu in the first place.Copying to the Gpu from the cpu can be a slow process, we would not want to have to individually transfer from the CPU to the GPU, do the calculation and then transfer the next peice of information from CPU to GPU. The overhead of all these copys would potentialy increase computation. Idealy we would want to copy the entire dataset over to the gpu to process in one go.Thus vastly decreaseing the copying overhead. The problem with this is unless useing a very powerful machine or a least a machine with a powerful GPU with a high amount of ram(random access memory) the data set will execeed the size of the memory in the gpu and crash.\n",
    "\n",
    "To avoid this problem a commonly used technique is to define a batch size that will represent the amount of datapoints copyed over to the gpu at a given time. then when processesing the data this value will be used to set the size of the batch of data to be copyed over. This gives us the benifit of the vastly more powerful calculation time of a gpu while avoiding the overhead of copying the information peice by peice and yet still not requireing excesive amounts of GPU memory.\n",
    "\n",
    "having our training done by the GPU is alot more efficent than when done on the cpu in some cases by more than a factor of 10.\n",
    "as seen in the image below a high range amd processer acives on average  440 examples/sec the equivelent intel processer acives a similar 415 exaples/sec then when we move on to the GPU's a low range mobile/laptop gpu achives a much higher 1190 examples/sec and then when we move onto a dedicated mid range GPU it jumps to an incredible 6500 examples/sec. speeds much high can be achived with even higher teirs of GPU as the Geforce 1070 discused here is a common mid range GPU retailing somewhere in the range of 400 euro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/cpuvsgpu.jpg\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "in this notebook we have discused the MNIST dataset and how to efficently load it into memory in python. we covered how the data set conists of thousands of 28x28 pixel images that are flatened into 784 dimensional vectors. these vectors are much easier to manipulate and use in machine learning than the previous pixel arays. we also showed how we can plot this multidensional vectors back into 28x28 pixel images to show the MNIST hand drawn numbers. Finaly we discused how we can optomise our dataset for GPU processing vastly increaseing the speed at which the dataset can be used for machine learning. The information gathered for this jupyter notebook was aquired from kaggles github repository on the MNIST dataset, the MNIST dataset website, Christopher Olah's blog post on visualising the MNIST dataset and finaly the metrics for the gpu and cpu comparisons where aquired from Andriy Lazorenko artcile on tensorflow perforce tests between cpu and gpu.\n",
    "\n",
    "https://github.com/tgjeon/kaggle-MNIST\n",
    "\n",
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "http://colah.github.io/posts/2014-10-Visualizing-MNIST/\n",
    "\n",
    "https://medium.com/@andriylazorenko/tensorflow-performance-test-cpu-vs-gpu-79fcd39170c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
